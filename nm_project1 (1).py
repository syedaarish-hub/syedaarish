# -*- coding: utf-8 -*-
"""NM_PROJECT1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1odwOR-2ysTN8G7uz-NLcMBR2VgCIPmCp
"""

from google.colab import files
import pandas as pd
uploaded = files.upload()
df = pd.read_csv(next(iter(uploaded)))
df.head()

from google.colab import sheets
sheet = sheets.InteractiveSheet(df=df)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
# Sample hardcoded dataset
data = {
    'text': [
        "Breaking news: aliens landed on Earth!",
        "Government releases economic growth data.",
        "Scientists discover water on Mars.",
        "Shocking! Man turns into lizard after vaccine.",
        "The president meets with foreign leaders.",
        "Fake cure for cancer goes viral on social media.",
        "NASA confirms Moon mission success.",
        "Flat Earth theory gains popularity again.",
        "Stock market hits new record high.",
        "Celebrity claims time travel is real."
    ],
    'label': [1, 0, 0, 1, 0, 1, 0, 1, 0, 1]  # 1 = fake, 0 = real
}
# Create DataFrame
df = pd.DataFrame(data)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(
    df['text'], df['label'], test_size=0.2, random_state=42
)
# TF-IDF Vectorization
vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Logistic Regression Model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# Predict
y_pred = model.predict(X_test_tfidf)

# Evaluation
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Visualization
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Real", "Fake"], yticklabels=["Real", "Fake"])
plt.title("Fake News Detection Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()
from sklearn.metrics import roc_curve, auc

# Probabilities for the positive class (Fake)
y_probs = model.predict_proba(X_test_tfidf)[:, 1] # Changed X_test to X_test_tfidf
# ROC curve values
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
# Plot ROC Curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd

# Get feature names and their coefficients
feature_names = vectorizer.get_feature_names_out()
coefs = model.coef_[0]

# Top positive (fake) and negative (real) indicators
top_n = 10
top_positive_indices = np.argsort(coefs)[-top_n:]
top_negative_indices = np.argsort(coefs)[:top_n]

top_features = np.concatenate([top_negative_indices, top_positive_indices])
colors = ['blue'] * top_n + ['red'] * top_n

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x=coefs[top_features], y=[feature_names[i] for i in top_features], palette=colors)
plt.title("Top Words Associated with Real (Blue) and Fake (Red) News")
plt.xlabel("Model Coefficient")
plt.ylabel("Word")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Generate synthetic data
np.random.seed(42)

# Fake news: higher subjectivity and polarity
fake_polarity = np.random.normal(loc=0.7, scale=0.2, size=100)
fake_subjectivity = np.random.normal(loc=0.8, scale=0.1, size=100)

# Real news: lower subjectivity and polarity
real_polarity = np.random.normal(loc=-0.1, scale=0.2, size=100)
real_subjectivity = np.random.normal(loc=0.3, scale=0.1, size=100)

# Create the plot
plt.figure(figsize=(10, 6))
plt.scatter(fake_polarity, fake_subjectivity, color='orange', label='Fake')
plt.scatter(real_polarity, real_subjectivity, color='blue', label='Real')

# Add labels and title
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')
plt.title('Distribution of Subjectivity and Polarity in Fake vs Real News')
plt.legend()
plt.grid(True)
plt.show()